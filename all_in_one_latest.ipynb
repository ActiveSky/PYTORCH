{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":370,"status":"ok","timestamp":1704640534393,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"27OO4IEO9g6T"},"outputs":[],"source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","\n","import matplotlib.pyplot as plt\n","\n","\n","\n","# set the super parameters\n","batch_size_train = 32\n","batch_size_test = 1000\n","\n","\n","def prepare_data():\n","    \"\"\"\n","    Prepare the MNIST dataset for training and testing.\n","\n","    Returns:\n","    train_loader (DataLoader): DataLoader object for training data.\n","    test_loader (DataLoader): DataLoader object for testing data.\n","    \"\"\"\n","    # 1.data preparation\n","    transform = transforms.Compose(\n","        [\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,)),\n","        ]\n","    )\n","    # 2.load train and test data\n","    trainset = datasets.MNIST(\n","        \"./data/MNIST_data/\", download=True, train=True, transform=transform\n","    )\n","    testset = datasets.MNIST(\n","        \"./data/MNIST_data/\", download=True, train=False, transform=transform\n","    )\n","\n","    # 3.create data loader\n","    train_loader = DataLoader(trainset, batch_size=batch_size_train, shuffle=True)\n","    test_loader = DataLoader(testset, batch_size=batch_size_test, shuffle=True)\n","\n","    return train_loader, test_loader\n","\n","def save_img(imgs, labels, num=0):\n","    # save image[0]  using plt\n","    plt.imshow(imgs[num].squeeze(0), cmap=\"gray\")\n","    plt.savefig(f\"./imgs/{labels[num]}.png\")\n","    return labels[num]\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704640534766,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"pm5ir9YC9g6V"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","# 1.full connected network\n","class Full_Net(nn.Module):\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the neural network model.\n","        \"\"\"\n","        super(Full_Net, self).__init__()\n","        self.fc1 = nn.Linear(784, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 784)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","# 2.convolutional neural network for number recognition\n","class Conv_Net(nn.Module):\n","    def __init__(self):\n","        super(Conv_Net, self).__init__()\n","\n","        self.conv_1=nn.Sequential(\n","            # 1. input 1*28*28 output 16*28*28\n","            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n","            # 2. batch normalization\n","            nn.BatchNorm2d(16),\n","            # 3. activation function\n","            nn.ReLU(),\n","            # 4. max pooling and output 16*14*14\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        )\n","        self.conv_2=nn.Sequential(\n","            # 卷积 输入：bs*16*14*14  输出：bs*32*14*14\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n","            # 归一化\n","            nn.BatchNorm2d(32),\n","            # 激活函数\n","            nn.ReLU(),\n","            # 最大池化：输入:bs*32*14*14  输出：bs*32*7*7\n","            nn.MaxPool2d(2)\n","        )\n","        # 第三层卷积，输入：bs*32*7*7 输出：bs*64*3*3\n","        self.conv_3 = nn.Sequential(\n","            # 卷积 输入：bs*32*7*7  输出：bs*64*3*3\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n","            # 归一化\n","            nn.BatchNorm2d(64),\n","            # 激活函数\n","            nn.ReLU(),\n","            # 最大池化：输入：bs*64*7*7 输出：bs*64*3*3\n","            nn.MaxPool2d(2)\n","        )\n","        # 自适应池化，将bs*64*3*3映射为bs*64*1*1\n","        self.advpool = nn.AdaptiveAvgPool2d((1, 1))\n","         # 全连接层\n","        self.fc = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        # 1. conv layer\n","        x = self.conv_1(x)\n","        x = self.conv_2(x)\n","        x = self.conv_3(x)\n","        # 2. adaptive pooling\n","        x = self.advpool(x)\n","        # 3. flatten\n","        x = x.view(x.size(0), -1)\n","        # 4. fc layer\n","        x = self.fc(x)\n","        return x\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704640534766,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"xq78vj539g6W"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.optim as optim\n","# from prepare_data import prepare_data\n","from torch.utils.tensorboard import SummaryWriter\n","\n","logger = SummaryWriter(\"./pytorch_tb/train_test\")\n","# super parameters\n","n_epochs = 10\n","learning_rate = 0.01\n","\n","\n","def net_train(net: nn.Module, trainloader: torch.utils.data.DataLoader):\n","    \"\"\"\n","    Train the neural network model.\n","    \"\"\"\n","    # set the optimizer and loss function\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    print(\"Start training...\")\n","    for epoch in range(n_epochs):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        # ensure the network is in training mode\n","        net.train()\n","        for i, data in enumerate(trainloader, 0):\n","\n","            inputs, labels = data\n","            # detect the device\n","            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","            inputs ,labels= inputs.to(device), labels.to(device)\n","\n","            # 1.input data\n","            outputs = net(inputs)  # forward\n","            # 2.calculate loss\n","            loss = criterion(outputs, labels)  # calculate the loss\n","            # 3.gradient to zero\n","            optimizer.zero_grad()  # zero the parameter gradients\n","            # 4.backpropagation\n","            loss.backward()  # backpropagation\n","            # 5.update parameters\n","            optimizer.step()  # update parameters\n","\n","            # Get the predicted labels\n","            _, predicted = torch.max(outputs, 1)\n","\n","            # Calculate the number of correct predictions\n","            correct = (predicted == labels).sum().item()\n","\n","            # Calculate the accuracy\n","            accuracy = correct / labels.size(0)\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 100 == 99:  # print every 2000 mini-batches\n","                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / 100))\n","                logger.add_scalar('training loss', running_loss / 100, epoch * len(trainloader) + i)\n","                logger.add_scalar('training accuracy', accuracy, epoch * len(trainloader) + i)\n","                running_loss = 0.0\n","    print(\"Finished Training\")\n","\n","\n","def net_test(net: nn.Module, testloader: torch.utils.data.DataLoader):\n","    print(\"Start testing...\")\n","    correct = 0\n","    total = 0\n","    # set model to evaluation mode\n","    net.eval()\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","             # detect the device\n","            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","            images ,labels= images.to(device), labels.to(device)\n","\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        print(\n","            \"Accuracy of the network on the test images: %d %%\"\n","            % (100 * correct / total)\n","        )\n","    print(\"Finished Testing\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704640534767,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"dDXJ6RrD9g6X"},"outputs":[],"source":["import torch\n","from PIL import Image\n","from torchvision import transforms\n","\n","def predict_digit(image_path, model):\n","    # 1.定义转换\n","    transform = transforms.Compose([\n","        transforms.Resize((28, 28)), # 调整图片大小\n","        transforms.ToTensor(), # 将PIL图片转换为Tensor\n","        transforms.Normalize((0.5,), (0.5,)) # 标准化\n","    ])\n","\n","    # 2.打开图片并应用转换\n","    image = Image.open(image_path).convert('L') # 转换为灰度图\n","    image = transform(image)\n","\n","    # 添加一个批次维度\n","    image = image.unsqueeze(0)\n","    # print image shape\n","    print(image.shape)\n","\n","    # 将模型设置为评估模式\n","    model.eval()\n","\n","    # predict result and probability\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted = torch.max(output.data, 1)\n","        print(\"Predicted digit:\", predicted.item())\n","        print(\"Predicted probability:\", torch.nn.functional.softmax(output.data, dim=1)[0][predicted.item()])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704640534767,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"iZhnJjV19g6X"},"outputs":[],"source":["\n","# multi-cpu training\n","\n","# torch.set_num_threads(4)  # 设置为你想要的线程数\n","\n","\n","def print_data(data_loader):\n","    # Assuming `data_loader` is an instance of torch.utils.data.DataLoader\n","    flag = 0\n","    for i, data in enumerate(data_loader):\n","        if flag == 1:\n","            break\n","        inputs, labels = data\n","        # detect the device\n","        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        inputs ,labels= inputs.to(device), labels.to(device)\n","        print(f\"Batch {i+1}:\")\n","        print(\"Inputs:\", inputs)\n","        print(\"Labels:\", labels)\n","        # print shape of inputs and labels\n","        print(\"Inputs shape:\", inputs.shape)\n","        print(\"Labels shape:\", labels.shape)\n","        flag += 1\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189206,"status":"ok","timestamp":1704640723970,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"xranq8mW-m2Q","outputId":"e74a4a76-8eeb-4b28-a6c9-b542b22f6e16"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","Start training...\n","[1,   100] loss: 0.832\n","[1,   200] loss: 0.253\n","[1,   300] loss: 0.167\n","[1,   400] loss: 0.147\n","[1,   500] loss: 0.118\n","[1,   600] loss: 0.088\n","[1,   700] loss: 0.106\n","[1,   800] loss: 0.106\n","[1,   900] loss: 0.082\n","[1,  1000] loss: 0.098\n","[1,  1100] loss: 0.079\n","[1,  1200] loss: 0.091\n","[1,  1300] loss: 0.078\n","[1,  1400] loss: 0.068\n","[1,  1500] loss: 0.072\n","[1,  1600] loss: 0.063\n","[1,  1700] loss: 0.065\n","[1,  1800] loss: 0.061\n","[2,   100] loss: 0.068\n","[2,   200] loss: 0.060\n","[2,   300] loss: 0.045\n","[2,   400] loss: 0.056\n","[2,   500] loss: 0.048\n","[2,   600] loss: 0.051\n","[2,   700] loss: 0.058\n","[2,   800] loss: 0.063\n","[2,   900] loss: 0.051\n","[2,  1000] loss: 0.061\n","[2,  1100] loss: 0.050\n","[2,  1200] loss: 0.045\n","[2,  1300] loss: 0.056\n","[2,  1400] loss: 0.056\n","[2,  1500] loss: 0.064\n","[2,  1600] loss: 0.055\n","[2,  1700] loss: 0.054\n","[2,  1800] loss: 0.051\n","[3,   100] loss: 0.040\n","[3,   200] loss: 0.041\n","[3,   300] loss: 0.038\n","[3,   400] loss: 0.037\n","[3,   500] loss: 0.035\n","[3,   600] loss: 0.045\n","[3,   700] loss: 0.046\n","[3,   800] loss: 0.053\n","[3,   900] loss: 0.045\n","[3,  1000] loss: 0.044\n","[3,  1100] loss: 0.043\n","[3,  1200] loss: 0.047\n","[3,  1300] loss: 0.048\n","[3,  1400] loss: 0.045\n","[3,  1500] loss: 0.038\n","[3,  1600] loss: 0.044\n","[3,  1700] loss: 0.044\n","[3,  1800] loss: 0.040\n","[4,   100] loss: 0.040\n","[4,   200] loss: 0.036\n","[4,   300] loss: 0.041\n","[4,   400] loss: 0.034\n","[4,   500] loss: 0.035\n","[4,   600] loss: 0.031\n","[4,   700] loss: 0.026\n","[4,   800] loss: 0.028\n","[4,   900] loss: 0.041\n","[4,  1000] loss: 0.030\n","[4,  1100] loss: 0.022\n","[4,  1200] loss: 0.026\n","[4,  1300] loss: 0.060\n","[4,  1400] loss: 0.047\n","[4,  1500] loss: 0.037\n","[4,  1600] loss: 0.036\n","[4,  1700] loss: 0.034\n","[4,  1800] loss: 0.029\n","[5,   100] loss: 0.031\n","[5,   200] loss: 0.022\n","[5,   300] loss: 0.016\n","[5,   400] loss: 0.025\n","[5,   500] loss: 0.029\n","[5,   600] loss: 0.025\n","[5,   700] loss: 0.044\n","[5,   800] loss: 0.036\n","[5,   900] loss: 0.031\n","[5,  1000] loss: 0.035\n","[5,  1100] loss: 0.025\n","[5,  1200] loss: 0.018\n","[5,  1300] loss: 0.024\n","[5,  1400] loss: 0.061\n","[5,  1500] loss: 0.032\n","[5,  1600] loss: 0.042\n","[5,  1700] loss: 0.037\n","[5,  1800] loss: 0.038\n","[6,   100] loss: 0.018\n","[6,   200] loss: 0.021\n","[6,   300] loss: 0.017\n","[6,   400] loss: 0.019\n","[6,   500] loss: 0.020\n","[6,   600] loss: 0.042\n","[6,   700] loss: 0.032\n","[6,   800] loss: 0.030\n","[6,   900] loss: 0.016\n","[6,  1000] loss: 0.028\n","[6,  1100] loss: 0.033\n","[6,  1200] loss: 0.023\n","[6,  1300] loss: 0.038\n","[6,  1400] loss: 0.025\n","[6,  1500] loss: 0.027\n","[6,  1600] loss: 0.021\n","[6,  1700] loss: 0.016\n","[6,  1800] loss: 0.026\n","[7,   100] loss: 0.021\n","[7,   200] loss: 0.016\n","[7,   300] loss: 0.015\n","[7,   400] loss: 0.025\n","[7,   500] loss: 0.027\n","[7,   600] loss: 0.026\n","[7,   700] loss: 0.017\n","[7,   800] loss: 0.030\n","[7,   900] loss: 0.026\n","[7,  1000] loss: 0.017\n","[7,  1100] loss: 0.019\n","[7,  1200] loss: 0.029\n","[7,  1300] loss: 0.035\n","[7,  1400] loss: 0.016\n","[7,  1500] loss: 0.029\n","[7,  1600] loss: 0.029\n","[7,  1700] loss: 0.031\n","[7,  1800] loss: 0.022\n","[8,   100] loss: 0.014\n","[8,   200] loss: 0.019\n","[8,   300] loss: 0.016\n","[8,   400] loss: 0.014\n","[8,   500] loss: 0.013\n","[8,   600] loss: 0.016\n","[8,   700] loss: 0.013\n","[8,   800] loss: 0.013\n","[8,   900] loss: 0.020\n","[8,  1000] loss: 0.023\n","[8,  1100] loss: 0.030\n","[8,  1200] loss: 0.026\n","[8,  1300] loss: 0.012\n","[8,  1400] loss: 0.023\n","[8,  1500] loss: 0.027\n","[8,  1600] loss: 0.024\n","[8,  1700] loss: 0.023\n","[8,  1800] loss: 0.025\n","[9,   100] loss: 0.022\n","[9,   200] loss: 0.020\n","[9,   300] loss: 0.016\n","[9,   400] loss: 0.017\n","[9,   500] loss: 0.012\n","[9,   600] loss: 0.014\n","[9,   700] loss: 0.020\n","[9,   800] loss: 0.025\n","[9,   900] loss: 0.015\n","[9,  1000] loss: 0.019\n","[9,  1100] loss: 0.020\n","[9,  1200] loss: 0.015\n","[9,  1300] loss: 0.034\n","[9,  1400] loss: 0.025\n","[9,  1500] loss: 0.025\n","[9,  1600] loss: 0.016\n","[9,  1700] loss: 0.019\n","[9,  1800] loss: 0.018\n","[10,   100] loss: 0.012\n","[10,   200] loss: 0.007\n","[10,   300] loss: 0.012\n","[10,   400] loss: 0.022\n","[10,   500] loss: 0.016\n","[10,   600] loss: 0.016\n","[10,   700] loss: 0.015\n","[10,   800] loss: 0.016\n","[10,   900] loss: 0.011\n","[10,  1000] loss: 0.014\n","[10,  1100] loss: 0.010\n","[10,  1200] loss: 0.015\n","[10,  1300] loss: 0.019\n","[10,  1400] loss: 0.016\n","[10,  1500] loss: 0.020\n","[10,  1600] loss: 0.020\n","[10,  1700] loss: 0.023\n","[10,  1800] loss: 0.025\n","Finished Training\n","consume time: 241.89014768600464\n"]}],"source":["\n","import time\n","if __name__ == \"__main__\":\n","    # set random seed\n","    random_seed = 1\n","    torch.manual_seed(random_seed)\n","\n","    # 1.get data\n","    trainloader, testloader = prepare_data()\n","\n","    # # print data\n","    # print_data(trainloader)\n","\n","    # 2.create network\n","    net = Conv_Net()\n","    # detect gpu\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(device)\n","    net.to(device)\n","    start=time.time()\n","    # 3.1 train network\n","    net_train(net, trainloader)\n","    end=time.time()\n","    print(\"consume time:\",end-start)\n","    # # 3.2 load weights\n","    # net.load_state_dict(torch.load(\"./weights/CovNet__weights.pth\"))\n","\n","    # # 4.save weights\n","    # torch.save(net.state_dict(), \"./weights/CovNet__weights.pth\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1917,"status":"ok","timestamp":1704640725874,"user":{"displayName":"JiKui Xie","userId":"03648797091471573739"},"user_tz":-480},"id":"JE5F9qewb5zY","outputId":"1471c09e-ff9a-4047-8f71-40d32fd4babd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start testing...\n","Accuracy of the network on the test images: 99 %\n","Finished Testing\n"]}],"source":["\n","    # 5.test network\n","    net_test(net, testloader)\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/ActiveSky/pytorch_learn/blob/num_reg/all_in_one.ipynb","timestamp":1704298393654}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
